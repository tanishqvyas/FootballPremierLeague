20/11/29 22:19:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
+--------------------+---------+-------------------+-----+----+------+------------+------+------+--------+--------+-----------+-------+-------------+------------+---------+---------------+------------+------+
|                name|birthArea|          birthDate| foot|role|height|passportArea|weight|    Id|numFouls|numGoals|numOwnGoals|passAcc|shotsOnTarget|normalPasses|keyPasses|accNormalPasses|accKeyPasses|rating|
+--------------------+---------+-------------------+-----+----+------+------------+------+------+--------+--------+-----------+-------+-------------+------------+---------+---------------+------------+------+
|Andr\u00e9 Ramalh...|   Brazil|1992-02-16 00:00:00|right|  DF|   182|      Brazil|    78| 65880|       0|       0|          0|      0|            0|           0|        0|              0|           0|   0.5|
|Tom\u00e1\u0161 H...| Slovakia|1985-09-17 00:00:00|right|  DF|   184|    Slovakia|    70|101555|       0|       0|          0|      0|            0|           0|        0|              0|           0|   0.5|
|Marc Muniesa Mart...|    Spain|1992-03-27 00:00:00| left|  DF|   179|       Spain|    72|  3340|       0|       0|          0|      0|            0|           0|        0|              0|           0|   0.5|
|    Leonardo Capezzi|    Italy|1995-03-28 00:00:00|right|  MD|   178|       Italy|    72|134429|       0|       0|          0|      0|            0|           0|        0|              0|           0|   0.5|
|Lionel Andr\u00e9...|Argentina|1987-06-24 00:00:00| left|  FW|   170|       Spain|    72|  3359|       0|       0|          0|      0|            0|           0|        0|              0|           0|   0.5|
+--------------------+---------+-------------------+-----+----+------+------------+------+------+--------+--------+-----------+-------+-------------+------------+---------+---------------+------------+------+
only showing top 5 rows

None
Sending :  {"req_type": 1, "date": "2021-02-21", "team1": {"name": "Everton FC", "player1": "Chris Gunter", "player2": "Matteo Darmian", "player3": "Ragnar Klavan", "player4": "Jan Vertonghen", "player5": "Joshua King", "player6": "Jordan Ayew", "player7": "Charlie Austin", "player8": "Simon Mignolet", "player9": "Stefano Sensi", "player10": "Samuel Bastien", "player11": "Gareth Barry"}, "team2": {"name": "Crystal Palace FC", "player1": "Vincent Kompany", "player2": "Kieran Trippier", "player3": "Trent Alexander-Arnold", "player4": "Ben Davies", "player5": "Eddie Nketiah", "player6": "Lukas Nmecha", "player7": "Michael Obafemi", "player8": "Hugo Lloris", "player9": "Victor Moses", "player10": "Rolando Aarons", "player11": "Dean Whitehead"}}

Exception in thread Thread-2:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/hadoop/FootballPremierLeague/backend/User_Interface.py", line 252, in start_user_service
    test_response = request_handler(request["req_type"], request, Metrics_RDD, Player_RDD)
  File "/home/hadoop/FootballPremierLeague/backend/User_Interface.py", line 204, in request_handler
    return handle_request_one(request)
  File "/home/hadoop/FootballPremierLeague/backend/User_Interface.py", line 50, in handle_request_one
    team1_cur_player_data = Player_RDD.filter(Player_RDD.name == team1_cur_player_name).collect()
NameError: name 'Player_RDD' is not defined
20/11/29 22:19:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:19:56 WARN BlockManager: Block input-0-1606668595800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:19:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:19:56 WARN BlockManager: Block input-0-1606668596000 replicated to only 0 peer(s) instead of 1 peers
{'status': 'Played', 'roundId': 4405654, 'gameweek': 1, 'teamsData': {'1609': {'scoreET': 0, 'coachId': 7845, 'side': 'home', 'teamId': 1609, 'score': 4, 'scoreP': 0, 'hasFormation': 1, 'formation': {'bench': [{'playerId': 20612, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 25662, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 7864, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 230020, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 26010, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}, {'playerId': 7879, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 7870, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}], 'lineup': [{'playerId': 370224, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 120339, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 7945, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}, {'playerId': 14869, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 25413, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}, {'playerId': 7868, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 3560, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 167145, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 3319, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 7882, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 49876, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'substitutions': [{'playerIn': 26010, 'playerOut': 370224, 'minute': 67}, {'playerIn': 7870, 'playerOut': 120339, 'minute': 67}, {'playerIn': 7879, 'playerOut': 7945, 'minute': 75}]}, 'scoreHT': 2}, '1631': {'scoreET': 0, 'coachId': 333782, 'side': 'away', 'teamId': 1631, 'score': 3, 'scoreP': 0, 'hasFormation': 1, 'formation': {'bench': [{'playerId': 119630, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8498, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 350976, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8066, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 285508, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 217078, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 283142, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'lineup': [{'playerId': 14763, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}, {'playerId': 192748, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8013, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8480, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8653, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 149019, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8488, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '94'}, {'playerId': 14853, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 265366, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 12829, 'ownGoals': '0', 'redCards': '0', 'goals': '2', 'yellowCards': '0'}, {'playerId': 26150, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'substitutions': [{'playerIn': 217078, 'playerOut': 14763, 'minute': 72}, {'playerIn': 285508, 'playerOut': 192748, 'minute': 82}, {'playerIn': 283142, 'playerOut': 8013, 'minute': 88}]}, 'scoreHT': 2}}, 'seasonId': 181150, 'dateutc': '2017-08-11 18:45:00', 'winner': 1609, 'venue': 'Emirates Stadium', 'wyId': 2499719, 'label': 'Arsenal - Leicester City, 4 - 3', 'date': 'August 11, 2017 at 8:45:00 PM GMT+2', 'referees': [{'refereeId': 385909, 'role': 'referee'}, {'refereeId': 385917, 'role': 'firstAssistant'}, {'refereeId': 384889, 'role': 'secondAssistant'}, {'refereeId': 381853, 'role': 'fourthOfficial'}], 'duration': 'Regular', 'competitionId': 364}
match data
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 25413, 'positions': [{'y': 49, 'x': 49}, {'y': 78, 'x': 31}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 2.7586489999999912, 'subEventId': 85, 'id': 177959171}
20/11/29 22:20:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:01 WARN BlockManager: Block input-0-1606668601000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 370224, 'positions': [{'y': 78, 'x': 31}, {'y': 75, 'x': 51}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 4.946850000000012, 'subEventId': 83, 'id': 177959172}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 75, 'x': 51}, {'y': 71, 'x': 35}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 6.54218800000001, 'subEventId': 82, 'id': 177959173}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 71, 'x': 35}, {'y': 95, 'x': 41}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 8.143394999999998, 'subEventId': 82, 'id': 177959174}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 95, 'x': 41}, {'y': 88, 'x': 72}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 10.302366000000006, 'subEventId': 85, 'id': 177959175}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1802}], 'playerId': 3319, 'positions': [{'y': 88, 'x': 72}, {'y': 75, 'x': 77}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 12.548934000000003, 'subEventId': 85, 'id': 177959177}
20/11/29 22:20:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:06 WARN BlockManager: Block input-0-1606668606000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 8653, 'positions': [{'y': 25, 'x': 23}, {'y': 15, 'x': 39}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 13.961228000000006, 'subEventId': 82, 'id': 177959186}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 8013, 'positions': [{'y': 15, 'x': 39}, {'y': 20, 'x': 33}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 14.765321, 'subEventId': 10, 'id': 177959189}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 0, 'positions': [{'y': 85, 'x': 61}, {'y': 80, 'x': 67}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 14.765321, 'subEventId': 10, 'id': 177961218}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1401}, {'id': 1801}], 'playerId': 167145, 'positions': [{'y': 80, 'x': 67}, {'y': 61, 'x': 59}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 15.320341000000013, 'subEventId': 82, 'id': 177959178}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 61, 'x': 59}, {'y': 45, 'x': 45}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 18.051874999999995, 'subEventId': 82, 'id': 177959179}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 14869, 'positions': [{'y': 45, 'x': 45}, {'y': 54, 'x': 71}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 20.426526999999993, 'subEventId': 83, 'id': 177959180}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 8653, 'positions': [{'y': 46, 'x': 29}, {'y': 41, 'x': 50}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 21.878309, 'subEventId': 10, 'id': 177959191}
20/11/29 22:20:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:11 WARN BlockManager: Block input-0-1606668611000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 25413, 'positions': [{'y': 54, 'x': 71}, {'y': 59, 'x': 50}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 22.551816000000002, 'subEventId': 10, 'id': 177959181}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 3560, 'positions': [{'y': 59, 'x': 50}, {'y': 69, 'x': 76}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 24.588310000000007, 'subEventId': 83, 'id': 177959182}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 8653, 'positions': [{'y': 31, 'x': 24}, {'y': 15, 'x': 42}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 25.904248999999993, 'subEventId': 82, 'id': 177959194}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 8013, 'positions': [{'y': 15, 'x': 42}, {'y': 26, 'x': 29}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 27.52769599999999, 'subEventId': 82, 'id': 177959195}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 265366, 'positions': [{'y': 26, 'x': 29}, {'y': 8, 'x': 37}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 29.980897999999996, 'subEventId': 85, 'id': 177959196}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8013, 'positions': [{'y': 8, 'x': 37}, {'y': 5, 'x': 23}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 31.163870000000003, 'subEventId': 85, 'id': 177959197}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 14853, 'positions': [{'y': 5, 'x': 23}, {'y': 19, 'x': 63}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 32.80561800000001, 'subEventId': 83, 'id': 177959202}
20/11/29 22:20:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:16 WARN BlockManager: Block input-0-1606668616000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 370224, 'positions': [{'y': 81, 'x': 37}, {'y': 95, 'x': 45}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 35.685081999999994, 'subEventId': 82, 'id': 177959184}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 14763, 'positions': [{'y': 5, 'x': 55}, {'y': 22, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 36.66126399999999, 'subEventId': 82, 'id': 177959204}
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 12829, 'positions': [{'y': 22, 'x': 67}, {'y': 15, 'x': 71}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 38.19187400000001, 'subEventId': 13, 'id': 177959205}
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 0, 'positions': [{'y': 78, 'x': 33}, {'y': 85, 'x': 29}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 38.19187400000001, 'subEventId': 13, 'id': 177961219}
{'eventId': 8, 'subEventName': 'Smart pass', 'tags': [{'id': 901}, {'id': 1802}], 'playerId': 14763, 'positions': [{'y': 15, 'x': 71}, {'y': 26, 'x': 81}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 39.94010900000001, 'subEventId': 86, 'id': 177959206}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 74, 'x': 19}, {'y': 53, 'x': 4}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 43.04583099999999, 'subEventId': 85, 'id': 177959185}
20/11/29 22:20:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:21 WARN BlockManager: Block input-0-1606668621000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:20:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:21 WARN BlockManager: Block input-0-1606668621200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Launch', 'tags': [{'id': 1801}], 'playerId': 7882, 'positions': [{'y': 53, 'x': 4}, {'y': 44, 'x': 40}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 44.425679, 'subEventId': 84, 'id': 177959187}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 192748, 'positions': [{'y': 56, 'x': 60}, {'y': 49, 'x': 56}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 47.71750800000001, 'subEventId': 10, 'id': 177959210}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 7945, 'positions': [{'y': 44, 'x': 40}, {'y': 51, 'x': 44}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 48.265872, 'subEventId': 10, 'id': 177959188}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 504}, {'id': 701}, {'id': 1802}], 'playerId': 149019, 'positions': [{'y': 49, 'x': 56}, {'y': 54, 'x': 45}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 49.18256600000001, 'subEventId': 12, 'id': 177959213}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 503}, {'id': 703}, {'id': 1801}], 'playerId': 7945, 'positions': [{'y': 51, 'x': 44}, {'y': 46, 'x': 55}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 50.33752100000001, 'subEventId': 11, 'id': 177959190}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 501}, {'id': 703}, {'id': 1801}], 'playerId': 7945, 'positions': [{'y': 46, 'x': 55}, {'y': 44, 'x': 64}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 51.66581099999999, 'subEventId': 11, 'id': 177959192}
20/11/29 22:20:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:26 WARN BlockManager: Block input-0-1606668626200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 502}, {'id': 701}, {'id': 1802}], 'playerId': 192748, 'positions': [{'y': 54, 'x': 45}, {'y': 56, 'x': 36}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 52.00954300000001, 'subEventId': 12, 'id': 177959215}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 502}, {'id': 1601}, {'id': 701}, {'id': 1802}], 'playerId': 8488, 'positions': [{'y': 56, 'x': 36}, {'y': 48, 'x': 36}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 52.66353599999999, 'subEventId': 12, 'id': 177959217}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 501}, {'id': 703}, {'id': 1801}], 'playerId': 7945, 'positions': [{'y': 44, 'x': 64}, {'y': 52, 'x': 64}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 53.25379799999999, 'subEventId': 11, 'id': 177959193}
{'eventId': 2, 'subEventName': 'Foul', 'tags': [], 'playerId': 8488, 'positions': [{'y': 48, 'x': 36}, {'y': 56, 'x': 36}], 'matchId': 2499719, 'eventName': 'Foul', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 54.36619999999999, 'subEventId': 20, 'id': 177959219}
{'eventId': 3, 'subEventName': 'Free Kick', 'tags': [{'id': 1801}], 'playerId': 0, 'positions': [{'y': 44, 'x': 65}, {'y': 31, 'x': 65}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 74.73714100000001, 'subEventId': 31, 'id': 177959198}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 31, 'x': 65}, {'y': 13, 'x': 90}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 76.625696, 'subEventId': 85, 'id': 177959199}
20/11/29 22:20:31 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:31 WARN BlockManager: Block input-0-1606668631200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 502}, {'id': 703}, {'id': 1801}], 'playerId': 7868, 'positions': [{'y': 13, 'x': 90}, {'y': 14, 'x': 96}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 83.67514599999998, 'subEventId': 11, 'id': 177959200}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 501}, {'id': 701}, {'id': 1802}], 'playerId': 149019, 'positions': [{'y': 87, 'x': 10}, {'y': 86, 'x': 4}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 83.706077, 'subEventId': 12, 'id': 177959222}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 501}, {'id': 703}, {'id': 1801}], 'playerId': 7868, 'positions': [{'y': 14, 'x': 96}, {'y': 3, 'x': 90}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 85.07404300000002, 'subEventId': 11, 'id': 177959201}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 502}, {'id': 701}, {'id': 1802}], 'playerId': 0, 'positions': [{'y': 86, 'x': 4}, {'y': 97, 'x': 10}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 85.07404300000002, 'subEventId': 12, 'id': 177961220}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 7868, 'positions': [{'y': 3, 'x': 90}, {'y': 13, 'x': 72}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 86.77345700000001, 'subEventId': 85, 'id': 177959203}
20/11/29 22:20:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:36 WARN BlockManager: Block input-0-1606668636200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 13, 'x': 72}, {'y': 86, 'x': 86}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 89.24938700000001, 'subEventId': 83, 'id': 177959207}
20/11/29 22:20:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:36 WARN BlockManager: Block input-0-1606668636400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 86, 'x': 86}, {'y': 71, 'x': 73}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 93.11554799999999, 'subEventId': 85, 'id': 177959208}
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 301}, {'id': 402}, {'id': 801}, {'id': 1801}], 'playerId': 120339, 'positions': [{'y': 71, 'x': 73}, {'y': 41, 'x': 88}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 93.96123499999999, 'subEventId': 80, 'id': 177959211}
{'eventId': 10, 'subEventName': 'Shot', 'tags': [{'id': 101}, {'id': 402}, {'id': 201}, {'id': 1205}, {'id': 1801}], 'playerId': 25413, 'positions': [{'y': 41, 'x': 88}, {'y': 0, 'x': 0}], 'matchId': 2499719, 'eventName': 'Shot', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 94.59578800000003, 'subEventId': 100, 'id': 177959212}
{'eventId': 9, 'subEventName': 'Reflexes', 'tags': [{'id': 101}, {'id': 1205}, {'id': 1802}], 'playerId': 8480, 'positions': [{'y': 100, 'x': 100}, {'y': 59, 'x': 12}], 'matchId': 2499719, 'eventName': 'Save attempt', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 96.97061400000001, 'subEventId': 90, 'id': 177959226}
20/11/29 22:20:41 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:41 WARN BlockManager: Block input-0-1606668641400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 8013, 'positions': [{'y': 6, 'x': 75}, {'y': 6, 'x': 82}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 147.157528, 'subEventId': 13, 'id': 177959231}
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 3319, 'positions': [{'y': 94, 'x': 25}, {'y': 94, 'x': 18}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 147.63374, 'subEventId': 13, 'id': 177959218}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1802}], 'playerId': 3319, 'positions': [{'y': 94, 'x': 18}, {'y': 92, 'x': 20}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 148.97274700000003, 'subEventId': 85, 'id': 177959220}
{'eventId': 7, 'subEventName': 'Touch', 'tags': [{'id': 1401}], 'playerId': 8013, 'positions': [{'y': 8, 'x': 80}, {'y': 28, 'x': 92}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 149.68212999999997, 'subEventId': 72, 'id': 177959233}
20/11/29 22:20:46 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:46 WARN BlockManager: Block input-0-1606668646400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 7, 'subEventName': 'Touch', 'tags': [], 'playerId': 12829, 'positions': [{'y': 28, 'x': 92}, {'y': 27, 'x': 89}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 151.86729000000003, 'subEventId': 72, 'id': 177959238}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 370224, 'positions': [{'y': 73, 'x': 11}, {'y': 73, 'x': 5}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 152.127886, 'subEventId': 12, 'id': 177959221}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 0, 'positions': [{'y': 27, 'x': 89}, {'y': 27, 'x': 95}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 152.127886, 'subEventId': 11, 'id': 177961221}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 12829, 'positions': [{'y': 27, 'x': 95}, {'y': 28, 'x': 94}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 153.404026, 'subEventId': 12, 'id': 177959236}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 0, 'positions': [{'y': 73, 'x': 5}, {'y': 72, 'x': 6}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 153.404026, 'subEventId': 11, 'id': 177961222}
{'eventId': 7, 'subEventName': 'Clearance', 'tags': [{'id': 1802}], 'playerId': 370224, 'positions': [{'y': 72, 'x': 6}, {'y': 100, 'x': 4}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 154.63865900000002, 'subEventId': 71, 'id': 177959223}
20/11/29 22:20:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:51 WARN BlockManager: Block input-0-1606668651400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 0, 'x': 96}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 157.045503, 'subEventId': 50, 'id': 177959242}
{'eventId': 3, 'subEventName': 'Throw in', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 0, 'x': 94}, {'y': 41, 'x': 93}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 175.308128, 'subEventId': 36, 'id': 177959244}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 8488, 'positions': [{'y': 41, 'x': 93}, {'y': 52, 'x': 85}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 178.23953899999998, 'subEventId': 10, 'id': 177959246}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 120339, 'positions': [{'y': 59, 'x': 7}, {'y': 48, 'x': 15}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 178.317724, 'subEventId': 10, 'id': 177959224}
{'eventId': 10, 'subEventName': 'Shot', 'tags': [{'id': 401}, {'id': 201}, {'id': 1211}, {'id': 1802}], 'playerId': 26150, 'positions': [{'y': 52, 'x': 85}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Shot', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 179.854785, 'subEventId': 100, 'id': 177959247}
20/11/29 22:20:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:20:56 WARN BlockManager: Block input-0-1606668656400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 38, 'x': 100}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 184.10022300000003, 'subEventId': 50, 'id': 177959251}
{'eventId': 3, 'subEventName': 'Goal kick', 'tags': [], 'playerId': 7882, 'positions': [{'y': 0, 'x': 0}, {'y': 44, 'x': 28}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 196.06685900000002, 'subEventId': 34, 'id': 177959227}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 44, 'x': 28}, {'y': 47, 'x': 43}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 198.85002100000003, 'subEventId': 85, 'id': 177959228}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 501}, {'id': 701}, {'id': 1802}], 'playerId': 8488, 'positions': [{'y': 53, 'x': 57}, {'y': 55, 'x': 55}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 200.55237599999998, 'subEventId': 12, 'id': 177959252}
20/11/29 22:21:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:01 WARN BlockManager: Block input-0-1606668661400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:21:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:01 WARN BlockManager: Block input-0-1606668661600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 502}, {'id': 703}, {'id': 1801}], 'playerId': 3319, 'positions': [{'y': 47, 'x': 43}, {'y': 45, 'x': 45}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 200.862749, 'subEventId': 11, 'id': 177959229}
{'eventId': 2, 'subEventName': 'Foul', 'tags': [], 'playerId': 8488, 'positions': [{'y': 55, 'x': 55}, {'y': 53, 'x': 57}], 'matchId': 2499719, 'eventName': 'Foul', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 202.040527, 'subEventId': 20, 'id': 177959253}
{'eventId': 3, 'subEventName': 'Free Kick', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 31, 'x': 39}, {'y': 61, 'x': 50}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 214.312946, 'subEventId': 31, 'id': 177959230}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 61, 'x': 50}, {'y': 43, 'x': 45}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 215.98235899999997, 'subEventId': 85, 'id': 177959232}
20/11/29 22:21:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:06 WARN BlockManager: Block input-0-1606668666600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 49876, 'positions': [{'y': 43, 'x': 45}, {'y': 86, 'x': 47}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 217.803357, 'subEventId': 83, 'id': 177959234}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1901}, {'id': 1401}, {'id': 1801}], 'playerId': 8013, 'positions': [{'y': 14, 'x': 53}, {'y': 7, 'x': 85}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 220.782446, 'subEventId': 85, 'id': 177959254}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 501}, {'id': 701}, {'id': 1802}], 'playerId': 3560, 'positions': [{'y': 93, 'x': 15}, {'y': 90, 'x': 4}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 226.31321400000002, 'subEventId': 12, 'id': 177959237}
20/11/29 22:21:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:11 WARN BlockManager: Block input-0-1606668671600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 1901}, {'id': 502}, {'id': 703}, {'id': 1801}], 'playerId': 12829, 'positions': [{'y': 7, 'x': 85}, {'y': 10, 'x': 96}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 227.006908, 'subEventId': 11, 'id': 177959257}
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 1901}, {'id': 401}, {'id': 2101}, {'id': 1802}], 'playerId': 12829, 'positions': [{'y': 10, 'x': 96}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 228.76425799999998, 'subEventId': 80, 'id': 177959258}
{'eventId': 7, 'subEventName': 'Touch', 'tags': [{'id': 1401}], 'playerId': 3560, 'positions': [{'y': 77, 'x': 3}, {'y': 84, 'x': 18}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 230.80848600000002, 'subEventId': 72, 'id': 177959239}
20/11/29 22:21:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:16 WARN BlockManager: Block input-0-1606668676600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 84, 'x': 18}, {'y': 95, 'x': 23}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 232.53819900000002, 'subEventId': 85, 'id': 177959240}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 2001}, {'id': 701}, {'id': 1802}], 'playerId': 3319, 'positions': [{'y': 95, 'x': 23}, {'y': 90, 'x': 8}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 233.70948900000002, 'subEventId': 11, 'id': 177959243}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 14853, 'positions': [{'y': 5, 'x': 77}, {'y': 10, 'x': 92}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 233.74561, 'subEventId': 12, 'id': 177959262}
20/11/29 22:21:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:21 WARN BlockManager: Block input-0-1606668681600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:21:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:22 WARN BlockManager: Block input-0-1606668681800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 401}, {'id': 1801}], 'playerId': 14853, 'positions': [{'y': 10, 'x': 92}, {'y': 37, 'x': 93}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 235.809436, 'subEventId': 80, 'id': 177959264}
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 37, 'x': 93}, {'y': 0, 'x': 100}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 236.935247, 'subEventId': 13, 'id': 177959266}
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 14869, 'positions': [{'y': 63, 'x': 7}, {'y': 100, 'x': 0}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 237.110293, 'subEventId': 13, 'id': 177959245}
20/11/29 22:21:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:27 WARN BlockManager: Block input-0-1606668686800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 29, 'x': 100}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 239.67726199999998, 'subEventId': 50, 'id': 177959267}
{'eventId': 3, 'subEventName': 'Corner', 'tags': [{'id': 1801}], 'playerId': 8013, 'positions': [{'y': 0, 'x': 100}, {'y': 6, 'x': 91}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 247.13447000000002, 'subEventId': 30, 'id': 177959268}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 6, 'x': 91}, {'y': 15, 'x': 77}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 249.17341599999997, 'subEventId': 85, 'id': 177959271}
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 402}, {'id': 801}, {'id': 1802}], 'playerId': 8013, 'positions': [{'y': 15, 'x': 77}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 251.06831899999997, 'subEventId': 80, 'id': 177959273}
20/11/29 22:21:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:32 WARN BlockManager: Block input-0-1606668691800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 4, 'subEventName': 'Goalkeeper leaving line', 'tags': [], 'playerId': 7882, 'positions': [{'y': 0, 'x': 0}, {'y': 85, 'x': 23}], 'matchId': 2499719, 'eventName': 'Goalkeeper leaving line', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 252.848204, 'subEventId': 40, 'id': 177959250}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 301}, {'id': 1801}], 'playerId': 8653, 'positions': [{'y': 66, 'x': 97}, {'y': 52, 'x': 96}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 252.93102399999998, 'subEventId': 82, 'id': 177959277}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 49876, 'positions': [{'y': 48, 'x': 4}, {'y': 48, 'x': 4}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 253.89308599999998, 'subEventId': 10, 'id': 177959248}
20/11/29 22:21:37 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:37 WARN BlockManager: Block input-0-1606668696800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 52, 'x': 96}, {'y': 52, 'x': 96}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 254.03630800000002, 'subEventId': 10, 'id': 177959279}
{'eventId': 10, 'subEventName': 'Shot', 'tags': [{'id': 101}, {'id': 403}, {'id': 201}, {'id': 1207}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 52, 'x': 96}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Shot', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 254.745027, 'subEventId': 100, 'id': 177959280}
{'eventId': 9, 'subEventName': 'Reflexes', 'tags': [{'id': 101}, {'id': 1207}, {'id': 1802}], 'playerId': 7882, 'positions': [{'y': 0, 'x': 0}, {'y': 48, 'x': 4}], 'matchId': 2499719, 'eventName': 'Save attempt', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 256.547834, 'subEventId': 90, 'id': 177959249}
20/11/29 22:21:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:42 WARN BlockManager: Block input-0-1606668701800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:21:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:42 WARN BlockManager: Block input-0-1606668702000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 370224, 'positions': [{'y': 85, 'x': 35}, {'y': 70, 'x': 86}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 320.235462, 'subEventId': 83, 'id': 177959256}
{'eventId': 7, 'subEventName': 'Touch', 'tags': [{'id': 1302}], 'playerId': 14853, 'positions': [{'y': 30, 'x': 14}, {'y': 31, 'x': 6}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 322.227608, 'subEventId': 72, 'id': 177959290}
20/11/29 22:21:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:47 WARN BlockManager: Block input-0-1606668707000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 7, 'subEventName': 'Touch', 'tags': [], 'playerId': 8480, 'positions': [{'y': 31, 'x': 6}, {'y': 41, 'x': 16}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 324.62300700000003, 'subEventId': 72, 'id': 177959291}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 8480, 'positions': [{'y': 41, 'x': 16}, {'y': 9, 'x': 62}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 340.684982, 'subEventId': 83, 'id': 177959295}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 9, 'x': 62}, {'y': 33, 'x': 72}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 342.852928, 'subEventId': 82, 'id': 177959296}
20/11/29 22:21:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:52 WARN BlockManager: Block input-0-1606668712000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 370224, 'positions': [{'y': 67, 'x': 28}, {'y': 50, 'x': 47}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 344.968625, 'subEventId': 10, 'id': 177959259}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 12829, 'positions': [{'y': 33, 'x': 72}, {'y': 50, 'x': 53}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 344.97733300000004, 'subEventId': 10, 'id': 177959297}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 7945, 'positions': [{'y': 50, 'x': 47}, {'y': 47, 'x': 53}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 346.556014, 'subEventId': 11, 'id': 177959261}
20/11/29 22:21:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:57 WARN BlockManager: Block input-0-1606668717000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:21:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:21:57 WARN BlockManager: Block input-0-1606668717200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 0, 'positions': [{'y': 50, 'x': 53}, {'y': 53, 'x': 47}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 346.556014, 'subEventId': 12, 'id': 177961224}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8488, 'positions': [{'y': 53, 'x': 47}, {'y': 51, 'x': 57}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 348.28910399999995, 'subEventId': 85, 'id': 177959298}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 26150, 'positions': [{'y': 51, 'x': 57}, {'y': 53, 'x': 55}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 349.19831, 'subEventId': 85, 'id': 177959299}
20/11/29 22:22:02 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:02 WARN BlockManager: Block input-0-1606668722200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 901}, {'id': 1802}], 'playerId': 192748, 'positions': [{'y': 53, 'x': 55}, {'y': 54, 'x': 87}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 349.80626199999995, 'subEventId': 83, 'id': 177959300}
{'eventId': 8, 'subEventName': 'Hand pass', 'tags': [{'id': 1801}], 'playerId': 7882, 'positions': [{'y': 46, 'x': 13}, {'y': 20, 'x': 33}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 355.197401, 'subEventId': 81, 'id': 177959263}
20/11/29 22:22:07 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:07 WARN BlockManager: Block input-0-1606668727200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 14869, 'positions': [{'y': 20, 'x': 33}, {'y': 23, 'x': 40}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 358.32967299999996, 'subEventId': 85, 'id': 177959265}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 23, 'x': 40}, {'y': 14, 'x': 40}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 360.99043099999994, 'subEventId': 85, 'id': 177959269}
20/11/29 22:22:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:12 WARN BlockManager: Block input-0-1606668732200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 7868, 'positions': [{'y': 14, 'x': 40}, {'y': 100, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 364.98598000000004, 'subEventId': 83, 'id': 177959270}
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 0, 'x': 33}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 369.60858399999995, 'subEventId': 50, 'id': 177959302}
{'eventId': 3, 'subEventName': 'Throw in', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 0, 'x': 32}, {'y': 6, 'x': 47}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 392.39299000000005, 'subEventId': 36, 'id': 177959304}
20/11/29 22:22:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:17 WARN BlockManager: Block input-0-1606668737200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:22:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:17 WARN BlockManager: Block input-0-1606668737400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 265366, 'positions': [{'y': 6, 'x': 47}, {'y': 10, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 393.678768, 'subEventId': 82, 'id': 177959305}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 370224, 'positions': [{'y': 90, 'x': 33}, {'y': 70, 'x': 71}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 395.56156999999996, 'subEventId': 83, 'id': 177959275}
20/11/29 22:22:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:22 WARN BlockManager: Block input-0-1606668742400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 25413, 'positions': [{'y': 70, 'x': 71}, {'y': 63, 'x': 71}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 397.881307, 'subEventId': 82, 'id': 177959276}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1401}, {'id': 1801}], 'playerId': 149019, 'positions': [{'y': 37, 'x': 29}, {'y': 3, 'x': 26}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 398.57293000000004, 'subEventId': 85, 'id': 177959308}
20/11/29 22:22:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:27 WARN BlockManager: Block input-0-1606668747400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 3, 'x': 26}, {'y': 8, 'x': 44}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 400.97083399999997, 'subEventId': 85, 'id': 177959310}
{'eventId': 8, 'subEventName': 'Smart pass', 'tags': [{'id': 901}, {'id': 1801}], 'playerId': 8013, 'positions': [{'y': 8, 'x': 44}, {'y': 17, 'x': 83}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 402.998466, 'subEventId': 86, 'id': 177959312}
20/11/29 22:22:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:32 WARN BlockManager: Block input-0-1606668752400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 12829, 'positions': [{'y': 17, 'x': 83}, {'y': 30, 'x': 83}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 408.42680199999995, 'subEventId': 85, 'id': 177959317}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 502}, {'id': 701}, {'id': 1802}], 'playerId': 14763, 'positions': [{'y': 30, 'x': 83}, {'y': 27, 'x': 89}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 410.001179, 'subEventId': 11, 'id': 177959322}
20/11/29 22:22:37 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:37 WARN BlockManager: Block input-0-1606668757400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 501}, {'id': 703}, {'id': 1801}], 'playerId': 0, 'positions': [{'y': 70, 'x': 17}, {'y': 73, 'x': 11}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 410.001179, 'subEventId': 12, 'id': 177961225}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 27, 'x': 89}, {'y': 28, 'x': 91}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 411.42878399999995, 'subEventId': 12, 'id': 177959326}
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 3560, 'positions': [{'y': 73, 'x': 11}, {'y': 72, 'x': 9}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 411.936148, 'subEventId': 11, 'id': 177959281}
20/11/29 22:22:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:42 WARN BlockManager: Block input-0-1606668762400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:22:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:42 WARN BlockManager: Block input-0-1606668762600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 72, 'x': 9}, {'y': 61, 'x': 14}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 412.85655799999995, 'subEventId': 85, 'id': 177959282}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 61, 'x': 14}, {'y': 39, 'x': 34}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 414.341812, 'subEventId': 85, 'id': 177959283}
20/11/29 22:22:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:47 WARN BlockManager: Block input-0-1606668767600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 39, 'x': 34}, {'y': 10, 'x': 53}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 418.028087, 'subEventId': 85, 'id': 177959284}
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 504}, {'id': 701}, {'id': 1802}], 'playerId': 14853, 'positions': [{'y': 90, 'x': 47}, {'y': 82, 'x': 41}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 421.06571499999995, 'subEventId': 12, 'id': 177959331}
20/11/29 22:22:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:52 WARN BlockManager: Block input-0-1606668772600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 503}, {'id': 703}, {'id': 1801}], 'playerId': 7868, 'positions': [{'y': 10, 'x': 53}, {'y': 18, 'x': 59}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 421.29478200000005, 'subEventId': 11, 'id': 177959287}
{'eventId': 7, 'subEventName': 'Acceleration', 'tags': [{'id': 1801}], 'playerId': 7868, 'positions': [{'y': 18, 'x': 59}, {'y': 33, 'x': 81}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 423.759467, 'subEventId': 70, 'id': 177959288}
20/11/29 22:22:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:57 WARN BlockManager: Block input-0-1606668777600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:22:58 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:22:58 WARN BlockManager: Block input-0-1606668777800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 10, 'subEventName': 'Shot', 'tags': [{'id': 401}, {'id': 201}, {'id': 1215}, {'id': 1802}], 'playerId': 7868, 'positions': [{'y': 33, 'x': 81}, {'y': 0, 'x': 0}], 'matchId': 2499719, 'eventName': 'Shot', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 425.824035, 'subEventId': 100, 'id': 177959289}
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 53, 'x': 2}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 427.39092600000004, 'subEventId': 50, 'id': 177959337}
20/11/29 22:23:03 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:03 WARN BlockManager: Block input-0-1606668782800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 3, 'subEventName': 'Goal kick', 'tags': [], 'playerId': 8480, 'positions': [{'y': 100, 'x': 100}, {'y': 47, 'x': 65}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 458.974297, 'subEventId': 34, 'id': 177959339}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 47, 'x': 65}, {'y': 52, 'x': 83}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 462.26596900000004, 'subEventId': 10, 'id': 177959340}
20/11/29 22:23:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:08 WARN BlockManager: Block input-0-1606668787800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 3560, 'positions': [{'y': 53, 'x': 35}, {'y': 48, 'x': 17}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 462.764499, 'subEventId': 10, 'id': 177959292}
{'eventId': 7, 'subEventName': 'Clearance', 'tags': [{'id': 1802}], 'playerId': 370224, 'positions': [{'y': 48, 'x': 17}, {'y': 100, 'x': 12}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 466.102129, 'subEventId': 71, 'id': 177959294}
20/11/29 22:23:13 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:13 WARN BlockManager: Block input-0-1606668792800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 0, 'x': 88}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 468.918533, 'subEventId': 50, 'id': 177959343}
{'eventId': 3, 'subEventName': 'Throw in', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 0, 'x': 73}, {'y': 7, 'x': 92}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 483.340689, 'subEventId': 36, 'id': 177959344}
20/11/29 22:23:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:18 WARN BlockManager: Block input-0-1606668797800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:23:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:18 WARN BlockManager: Block input-0-1606668798000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8013, 'positions': [{'y': 7, 'x': 92}, {'y': 6, 'x': 85}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 485.09508300000005, 'subEventId': 85, 'id': 177959346}
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 401}, {'id': 1802}], 'playerId': 14853, 'positions': [{'y': 6, 'x': 85}, {'y': 38, 'x': 92}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 486.18351700000005, 'subEventId': 80, 'id': 177959347}
20/11/29 22:23:23 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:23 WARN BlockManager: Block input-0-1606668803000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 7, 'subEventName': 'Clearance', 'tags': [{'id': 1401}, {'id': 1802}], 'playerId': 370224, 'positions': [{'y': 62, 'x': 8}, {'y': 85, 'x': 50}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 488.01946799999996, 'subEventId': 71, 'id': 177959301}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8653, 'positions': [{'y': 15, 'x': 50}, {'y': 36, 'x': 39}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 491.98057300000005, 'subEventId': 85, 'id': 177959349}
20/11/29 22:23:28 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:28 WARN BlockManager: Block input-0-1606668808000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 504}, {'id': 703}, {'id': 1801}], 'playerId': 8488, 'positions': [{'y': 36, 'x': 39}, {'y': 13, 'x': 49}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 493.929879, 'subEventId': 11, 'id': 177959350}
20/11/29 22:23:33 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:33 WARN BlockManager: Block input-0-1606668813000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 503}, {'id': 701}, {'id': 1802}], 'playerId': 25413, 'positions': [{'y': 64, 'x': 61}, {'y': 87, 'x': 51}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 494.461238, 'subEventId': 12, 'id': 177959303}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8488, 'positions': [{'y': 13, 'x': 49}, {'y': 4, 'x': 63}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 496.18985, 'subEventId': 85, 'id': 177959353}
20/11/29 22:23:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:38 WARN BlockManager: Block input-0-1606668818000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:23:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:38 WARN BlockManager: Block input-0-1606668818200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 901}, {'id': 1802}], 'playerId': 14853, 'positions': [{'y': 4, 'x': 63}, {'y': 96, 'x': 100}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 498.38919699999997, 'subEventId': 83, 'id': 177959354}
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 96, 'x': 100}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 506.70697500000006, 'subEventId': 50, 'id': 177959359}
20/11/29 22:23:43 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:43 WARN BlockManager: Block input-0-1606668823200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 3, 'subEventName': 'Goal kick', 'tags': [], 'playerId': 7882, 'positions': [{'y': 0, 'x': 0}, {'y': 47, 'x': 24}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 517.797223, 'subEventId': 34, 'id': 177959306}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 47, 'x': 24}, {'y': 57, 'x': 34}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 519.222798, 'subEventId': 85, 'id': 177959307}
20/11/29 22:23:48 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:48 WARN BlockManager: Block input-0-1606668828200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 57, 'x': 34}, {'y': 80, 'x': 25}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 520.828507, 'subEventId': 85, 'id': 177959309}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 370224, 'positions': [{'y': 80, 'x': 25}, {'y': 25, 'x': 33}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 525.366124, 'subEventId': 85, 'id': 177959311}
20/11/29 22:23:53 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:53 WARN BlockManager: Block input-0-1606668833200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 25, 'x': 33}, {'y': 33, 'x': 52}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 528.686017, 'subEventId': 85, 'id': 177959313}
20/11/29 22:23:58 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:58 WARN BlockManager: Block input-0-1606668838200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:23:58 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:23:58 WARN BlockManager: Block input-0-1606668838400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 7945, 'positions': [{'y': 33, 'x': 52}, {'y': 23, 'x': 61}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 529.895189, 'subEventId': 85, 'id': 177959314}
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 23, 'x': 61}, {'y': 96, 'x': 77}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 533.69431, 'subEventId': 83, 'id': 177959316}
20/11/29 22:24:03 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:03 WARN BlockManager: Block input-0-1606668843400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 96, 'x': 77}, {'y': 68, 'x': 68}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 536.73443, 'subEventId': 85, 'id': 177959319}
20/11/29 22:24:08 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:08 WARN BlockManager: Block input-0-1606668848400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 68, 'x': 68}, {'y': 68, 'x': 58}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 539.886144, 'subEventId': 85, 'id': 177959320}
20/11/29 22:24:13 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:13 WARN BlockManager: Block input-0-1606668853400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 68, 'x': 58}, {'y': 75, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 542.348946, 'subEventId': 85, 'id': 177959321}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 75, 'x': 67}, {'y': 89, 'x': 78}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 544.680161, 'subEventId': 85, 'id': 177959323}
20/11/29 22:24:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:18 WARN BlockManager: Block input-0-1606668858400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:24:18 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:18 WARN BlockManager: Block input-0-1606668858600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 89, 'x': 78}, {'y': 75, 'x': 64}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 546.165167, 'subEventId': 85, 'id': 177959324}
20/11/29 22:24:23 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:23 WARN BlockManager: Block input-0-1606668863600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 75, 'x': 64}, {'y': 54, 'x': 47}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 549.607294, 'subEventId': 85, 'id': 177959325}
20/11/29 22:24:28 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:28 WARN BlockManager: Block input-0-1606668868600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 54, 'x': 47}, {'y': 22, 'x': 68}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 552.277776, 'subEventId': 85, 'id': 177959327}
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 22, 'x': 68}, {'y': 48, 'x': 53}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 558.057534, 'subEventId': 85, 'id': 177959328}
20/11/29 22:24:33 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:33 WARN BlockManager: Block input-0-1606668873600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 48, 'x': 53}, {'y': 76, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 560.675999, 'subEventId': 85, 'id': 177959330}
20/11/29 22:24:38 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:38 WARN BlockManager: Block input-0-1606668878600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:24:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:39 WARN BlockManager: Block input-0-1606668878800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 370224, 'positions': [{'y': 76, 'x': 67}, {'y': 59, 'x': 66}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 563.734069, 'subEventId': 85, 'id': 177959332}
20/11/29 22:24:44 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:44 WARN BlockManager: Block input-0-1606668883800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 59, 'x': 66}, {'y': 27, 'x': 69}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 566.299631, 'subEventId': 85, 'id': 177959333}
20/11/29 22:24:49 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:49 WARN BlockManager: Block input-0-1606668888800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 27, 'x': 69}, {'y': 6, 'x': 88}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 568.593815, 'subEventId': 85, 'id': 177959334}
20/11/29 22:24:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:54 WARN BlockManager: Block input-0-1606668893800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:24:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:54 WARN BlockManager: Block input-0-1606668894000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Cross', 'tags': [{'id': 401}, {'id': 801}, {'id': 1801}], 'playerId': 7868, 'positions': [{'y': 6, 'x': 88}, {'y': 86, 'x': 94}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 571.101335, 'subEventId': 80, 'id': 177959336}
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 167145, 'positions': [{'y': 86, 'x': 94}, {'y': 62, 'x': 97}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 574.608133, 'subEventId': 82, 'id': 177959338}
20/11/29 22:24:59 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:24:59 WARN BlockManager: Block input-0-1606668899000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 7, 'subEventName': 'Clearance', 'tags': [{'id': 1401}, {'id': 1802}], 'playerId': 8653, 'positions': [{'y': 38, 'x': 3}, {'y': 9, 'x': 0}], 'matchId': 2499719, 'eventName': 'Others on the ball', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 575.698447, 'subEventId': 71, 'id': 177959370}
20/11/29 22:25:04 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:04 WARN BlockManager: Block input-0-1606668904000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 9, 'x': 0}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 578.603998, 'subEventId': 50, 'id': 177959371}
{'eventId': 3, 'subEventName': 'Corner', 'tags': [{'id': 801}, {'id': 1801}], 'playerId': 49876, 'positions': [{'y': 100, 'x': 100}, {'y': 34, 'x': 89}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 598.145995, 'subEventId': 30, 'id': 177959342}
20/11/29 22:25:09 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:09 WARN BlockManager: Block input-0-1606668909000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 265366, 'positions': [{'y': 66, 'x': 11}, {'y': 62, 'x': 9}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 600.542239, 'subEventId': 10, 'id': 177959374}
20/11/29 22:25:14 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:14 WARN BlockManager: Block input-0-1606668914000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:25:14 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:14 WARN BlockManager: Block input-0-1606668914200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 3560, 'positions': [{'y': 34, 'x': 89}, {'y': 38, 'x': 91}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 600.581934, 'subEventId': 10, 'id': 177959345}
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 265366, 'positions': [{'y': 62, 'x': 9}, {'y': 100, 'x': 6}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 600.711946, 'subEventId': 10, 'id': 177959376}
20/11/29 22:25:19 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:19 WARN BlockManager: Block input-0-1606668919200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 0, 'positions': [{'y': 38, 'x': 91}, {'y': 0, 'x': 94}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 600.711946, 'subEventId': 10, 'id': 177961227}
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 100, 'x': 4}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 605.603263, 'subEventId': 50, 'id': 177959377}
20/11/29 22:25:24 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:24 WARN BlockManager: Block input-0-1606668924200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 3, 'subEventName': 'Throw in', 'tags': [{'id': 1801}], 'playerId': 149019, 'positions': [{'y': 100, 'x': 6}, {'y': 95, 'x': 30}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 628.875105, 'subEventId': 36, 'id': 177959378}
20/11/29 22:25:29 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:29 WARN BlockManager: Block input-0-1606668929200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 14763, 'positions': [{'y': 95, 'x': 30}, {'y': 79, 'x': 37}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 629.945818, 'subEventId': 82, 'id': 177959380}
20/11/29 22:25:29 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:29 WARN BlockManager: Block input-0-1606668929400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 14869, 'positions': [{'y': 21, 'x': 63}, {'y': 23, 'x': 70}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 631.519012, 'subEventId': 82, 'id': 177959351}
20/11/29 22:25:34 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:34 WARN BlockManager: Block input-0-1606668934400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 23, 'x': 70}, {'y': 24, 'x': 57}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 632.220757, 'subEventId': 82, 'id': 177959352}
20/11/29 22:25:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:39 WARN BlockManager: Block input-0-1606668939400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 24, 'x': 57}, {'y': 43, 'x': 65}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 633.841517, 'subEventId': 85, 'id': 177959355}
20/11/29 22:25:44 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:44 WARN BlockManager: Block input-0-1606668944400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 43, 'x': 65}, {'y': 86, 'x': 65}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 636.743072, 'subEventId': 85, 'id': 177959356}
20/11/29 22:25:49 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:49 WARN BlockManager: Block input-0-1606668949400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 167145, 'positions': [{'y': 86, 'x': 65}, {'y': 42, 'x': 67}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 639.057997, 'subEventId': 85, 'id': 177959357}
20/11/29 22:25:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:54 WARN BlockManager: Block input-0-1606668954400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:25:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:54 WARN BlockManager: Block input-0-1606668954600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 42, 'x': 67}, {'y': 14, 'x': 62}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 642.090366, 'subEventId': 85, 'id': 177959358}
20/11/29 22:25:59 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:25:59 WARN BlockManager: Block input-0-1606668959600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 14869, 'positions': [{'y': 14, 'x': 62}, {'y': 8, 'x': 69}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 644.637404, 'subEventId': 85, 'id': 177959360}
20/11/29 22:26:04 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:04 WARN BlockManager: Block input-0-1606668964600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 7868, 'positions': [{'y': 8, 'x': 69}, {'y': 22, 'x': 70}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 645.348272, 'subEventId': 85, 'id': 177959362}
20/11/29 22:26:09 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:09 WARN BlockManager: Block input-0-1606668969600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 120339, 'positions': [{'y': 22, 'x': 70}, {'y': 31, 'x': 56}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 646.298737, 'subEventId': 85, 'id': 177959363}
20/11/29 22:26:14 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:14 WARN BlockManager: Block input-0-1606668974200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3560, 'positions': [{'y': 31, 'x': 56}, {'y': 12, 'x': 66}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 649.15001, 'subEventId': 85, 'id': 177959364}
20/11/29 22:26:20 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:20 WARN BlockManager: Block input-0-1606668979800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 7868, 'positions': [{'y': 12, 'x': 66}, {'y': 54, 'x': 55}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 650.519088, 'subEventId': 85, 'id': 177959365}
20/11/29 22:26:25 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:25 WARN BlockManager: Block input-0-1606668984800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:30 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:30 WARN BlockManager: Block input-0-1606668989800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:30 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:30 WARN BlockManager: Block input-0-1606668990000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 49876, 'positions': [{'y': 54, 'x': 55}, {'y': 58, 'x': 71}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 653.158902, 'subEventId': 85, 'id': 177959366}
20/11/29 22:26:35 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:35 WARN BlockManager: Block input-0-1606668994600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:35 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:35 WARN BlockManager: Block input-0-1606668995000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:40 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:40 WARN BlockManager: Block input-0-1606669000000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 3319, 'positions': [{'y': 58, 'x': 71}, {'y': 76, 'x': 53}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 654.543901, 'subEventId': 85, 'id': 177959367}
20/11/29 22:26:45 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:45 WARN BlockManager: Block input-0-1606669005000 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'High pass', 'tags': [{'id': 1802}], 'playerId': 370224, 'positions': [{'y': 76, 'x': 53}, {'y': 87, 'x': 95}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 656.021673, 'subEventId': 83, 'id': 177959368}
20/11/29 22:26:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:50 WARN BlockManager: Block input-0-1606669009800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:50 WARN BlockManager: Block input-0-1606669010000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:55 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:55 WARN BlockManager: Block input-0-1606669015000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:26:55 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:26:55 WARN BlockManager: Block input-0-1606669015200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 5, 'subEventName': 'Ball out of the field', 'tags': [], 'playerId': 0, 'positions': [{'y': 13, 'x': 5}, {'y': 100, 'x': 100}], 'matchId': 2499719, 'eventName': 'Interruption', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 659.628954, 'subEventId': 50, 'id': 177959382}
20/11/29 22:27:00 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:00 WARN BlockManager: Block input-0-1606669020200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 3, 'subEventName': 'Goal kick', 'tags': [], 'playerId': 8480, 'positions': [{'y': 100, 'x': 100}, {'y': 28, 'x': 67}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 683.236107, 'subEventId': 34, 'id': 177959384}
20/11/29 22:27:05 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:05 WARN BlockManager: Block input-0-1606669025000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:05 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:05 WARN BlockManager: Block input-0-1606669025200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:05 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:05 WARN BlockManager: Block input-0-1606669025400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 28, 'x': 67}, {'y': 37, 'x': 74}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 686.898579, 'subEventId': 10, 'id': 177959386}
20/11/29 22:27:10 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:10 WARN BlockManager: Block input-0-1606669030200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:10 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:10 WARN BlockManager: Block input-0-1606669030400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:15 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:15 WARN BlockManager: Block input-0-1606669035400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Air duel', 'tags': [{'id': 702}, {'id': 1801}], 'playerId': 370224, 'positions': [{'y': 72, 'x': 33}, {'y': 63, 'x': 26}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 686.903195, 'subEventId': 10, 'id': 177959372}
20/11/29 22:27:20 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:20 WARN BlockManager: Block input-0-1606669040200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:20 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:20 WARN BlockManager: Block input-0-1606669040400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:21 WARN BlockManager: Block input-0-1606669040600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:25 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:25 WARN BlockManager: Block input-0-1606669045400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 701}, {'id': 1802}], 'playerId': 12829, 'positions': [{'y': 37, 'x': 74}, {'y': 59, 'x': 74}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 688.046924, 'subEventId': 13, 'id': 177959388}
20/11/29 22:27:30 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:30 WARN BlockManager: Block input-0-1606669050600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:35 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:35 WARN BlockManager: Block input-0-1606669055600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground loose ball duel', 'tags': [{'id': 703}, {'id': 1801}], 'playerId': 3560, 'positions': [{'y': 63, 'x': 26}, {'y': 41, 'x': 26}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 688.498856, 'subEventId': 13, 'id': 177959373}
20/11/29 22:27:40 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:40 WARN BlockManager: Block input-0-1606669060600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Head pass', 'tags': [{'id': 1802}], 'playerId': 14869, 'positions': [{'y': 41, 'x': 26}, {'y': 59, 'x': 31}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 690.988455, 'subEventId': 82, 'id': 177959375}
20/11/29 22:27:45 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:45 WARN BlockManager: Block input-0-1606669065600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:50 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:50 WARN BlockManager: Block input-0-1606669070600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:51 WARN BlockManager: Block input-0-1606669070800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 26150, 'positions': [{'y': 41, 'x': 69}, {'y': 39, 'x': 65}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 692.552657, 'subEventId': 85, 'id': 177959391}
20/11/29 22:27:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:56 WARN BlockManager: Block input-0-1606669075800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:27:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:27:56 WARN BlockManager: Block input-0-1606669076000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:01 WARN BlockManager: Block input-0-1606669080800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 265366, 'positions': [{'y': 39, 'x': 65}, {'y': 64, 'x': 61}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 694.038611, 'subEventId': 85, 'id': 177959392}
20/11/29 22:28:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:06 WARN BlockManager: Block input-0-1606669085800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:06 WARN BlockManager: Block input-0-1606669086000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:11 WARN BlockManager: Block input-0-1606669090600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:11 WARN BlockManager: Block input-0-1606669091000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:16 WARN BlockManager: Block input-0-1606669095800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 149019, 'positions': [{'y': 64, 'x': 61}, {'y': 7, 'x': 59}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 696.321312, 'subEventId': 85, 'id': 177959394}
20/11/29 22:28:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:21 WARN BlockManager: Block input-0-1606669101000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:21 WARN BlockManager: Block input-0-1606669101200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:26 WARN BlockManager: Block input-0-1606669106000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:26 WARN BlockManager: Block input-0-1606669106200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 14853, 'positions': [{'y': 7, 'x': 59}, {'y': 17, 'x': 40}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 702.436987, 'subEventId': 85, 'id': 177959396}
20/11/29 22:28:31 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:31 WARN BlockManager: Block input-0-1606669110800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:36 WARN BlockManager: Block input-0-1606669116200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8653, 'positions': [{'y': 17, 'x': 40}, {'y': 21, 'x': 66}], 'matchId': 2499719, 'eventName': 'Pass', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 705.298789, 'subEventId': 85, 'id': 177959397}
20/11/29 22:28:41 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:41 WARN BlockManager: Block input-0-1606669121200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:46 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:46 WARN BlockManager: Block input-0-1606669126200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:46 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:46 WARN BlockManager: Block input-0-1606669126400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:51 WARN BlockManager: Block input-0-1606669131200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:51 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:51 WARN BlockManager: Block input-0-1606669131600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground defending duel', 'tags': [{'id': 504}, {'id': 701}, {'id': 1802}], 'playerId': 370224, 'positions': [{'y': 79, 'x': 34}, {'y': 71, 'x': 33}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 707.392728, 'subEventId': 12, 'id': 177959379}
20/11/29 22:28:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:56 WARN BlockManager: Block input-0-1606669136400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:28:56 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:28:56 WARN BlockManager: Block input-0-1606669136600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:01 WARN BlockManager: Block input-0-1606669141200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:01 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:01 WARN BlockManager: Block input-0-1606669141400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:06 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:06 WARN BlockManager: Block input-0-1606669146400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 503}, {'id': 703}, {'id': 1801}], 'playerId': 14763, 'positions': [{'y': 21, 'x': 66}, {'y': 29, 'x': 67}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 707.402393, 'subEventId': 11, 'id': 177959399}
20/11/29 22:29:11 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:11 WARN BlockManager: Block input-0-1606669151400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:12 WARN BlockManager: Block input-0-1606669151600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:16 WARN BlockManager: Block input-0-1606669156400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:16 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:16 WARN BlockManager: Block input-0-1606669156600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:17 WARN BlockManager: Block input-0-1606669156800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:21 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:21 WARN BlockManager: Block input-0-1606669161400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:22 WARN BlockManager: Block input-0-1606669161600 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 2, 'subEventName': 'Foul', 'tags': [], 'playerId': 370224, 'positions': [{'y': 71, 'x': 33}, {'y': 79, 'x': 34}], 'matchId': 2499719, 'eventName': 'Foul', 'teamId': 1609, 'matchPeriod': '1H', 'eventSec': 708.974878, 'subEventId': 20, 'id': 177959381}
20/11/29 22:29:26 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:26 WARN BlockManager: Block input-0-1606669166400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:31 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:31 WARN BlockManager: Block input-0-1606669171600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:32 WARN BlockManager: Block input-0-1606669171800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:36 WARN BlockManager: Block input-0-1606669176400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:36 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:36 WARN BlockManager: Block input-0-1606669176600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:37 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:37 WARN BlockManager: Block input-0-1606669176800 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 3, 'subEventName': 'Free Kick', 'tags': [{'id': 1801}], 'playerId': 8013, 'positions': [{'y': 13, 'x': 66}, {'y': 13, 'x': 71}], 'matchId': 2499719, 'eventName': 'Free Kick', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 733.801542, 'subEventId': 31, 'id': 177959403}
20/11/29 22:29:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:42 WARN BlockManager: Block input-0-1606669181600 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:42 WARN BlockManager: Block input-0-1606669181800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:42 WARN BlockManager: Block input-0-1606669182000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:47 WARN BlockManager: Block input-0-1606669186800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:47 WARN BlockManager: Block input-0-1606669187000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:52 WARN BlockManager: Block input-0-1606669191800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:52 WARN BlockManager: Block input-0-1606669192000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:52 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:52 WARN BlockManager: Block input-0-1606669192200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:29:57 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:29:57 WARN BlockManager: Block input-0-1606669197000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:02 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:02 WARN BlockManager: Block input-0-1606669201800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:02 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:02 WARN BlockManager: Block input-0-1606669202000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:02 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:02 WARN BlockManager: Block input-0-1606669202200 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 1, 'subEventName': 'Ground attacking duel', 'tags': [{'id': 501}, {'id': 703}, {'id': 1801}], 'playerId': 26150, 'positions': [{'y': 13, 'x': 71}, {'y': 21, 'x': 70}], 'matchId': 2499719, 'eventName': 'Duel', 'teamId': 1631, 'matchPeriod': '1H', 'eventSec': 736.866709, 'subEventId': 11, 'id': 177959405}
20/11/29 22:30:07 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:07 WARN BlockManager: Block input-0-1606669207000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:12 WARN BlockManager: Block input-0-1606669212000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:12 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:12 WARN BlockManager: Block input-0-1606669212200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:17 WARN BlockManager: Block input-0-1606669216800 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:17 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:17 WARN BlockManager: Block input-0-1606669217200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:22 WARN BlockManager: Block input-0-1606669222000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:22 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:22 WARN BlockManager: Block input-0-1606669222200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:27 WARN BlockManager: Block input-0-1606669227200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:27 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:27 WARN BlockManager: Block input-0-1606669227400 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:32 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:32 WARN BlockManager: Block input-0-1606669232200 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:39 ERROR Utils: Uncaught exception in thread executor-heartbeater
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:548)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:552)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:102)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:913)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:200)
	at org.apache.spark.executor.Executor$$Lambda$545/1018918609.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1932)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
20/11/29 22:30:39 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:39 WARN BlockManager: Block input-0-1606669239000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:39 ERROR JobScheduler: Error running job streaming job 1606668600000 ms.0
org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/streaming/dstream.py", line 161, in <lambda>
    func = lambda t, rdd: old_func(rdd)
  File "main.py", line 125, in calc_metrics
    metrics_values=df3.collect()[0]
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py", line 596, in collect
    sock_info = self._jdf.collectToPython()
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o10115.collectToPython.
: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)
	at org.codehaus.janino.UnitCompiler.access$5100(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3564)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$IfStatement.accept(Java.java:3140)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)
	at org.codehaus.janino.UnitCompiler.access$5100(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3564)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$IfStatement.accept(Java.java:3140)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{'status': 'Played', 'roundId': 4405654, 'gameweek': 1, 'teamsData': {'1651': {'scoreET': 0, 'coachId': 8093, 'side': 'home', 'teamId': 1651, 'score': 0, 'scoreP': 0, 'hasFormation': 1, 'formation': {'bench': [{'playerId': 11150, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 71, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 15301, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 9622, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 62091, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8416, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 25950, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'lineup': [{'playerId': 255935, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 3657, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 247248, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8242, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 61390, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 9097, 'ownGoals': '1', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 15526, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8086, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 64966, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 466, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 3278, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'substitutions': [{'playerIn': 62091, 'playerOut': 255935, 'minute': 24}, {'playerIn': 8416, 'playerOut': 3657, 'minute': 60}, {'playerIn': 25950, 'playerOut': 247248, 'minute': 75}]}, 'scoreHT': 0}, '1625': {'scoreET': 0, 'coachId': 267136, 'side': 'away', 'teamId': 1625, 'score': 2, 'scoreP': 0, 'hasFormation': 1, 'formation': {'bench': [{'playerId': 3662, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 70085, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8324, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 447205, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 265673, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 245364, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 11066, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '82'}], 'lineup': [{'playerId': 70083, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 340386, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '29'}, {'playerId': 8325, 'ownGoals': '0', 'redCards': '0', 'goals': '1', 'yellowCards': '0'}, {'playerId': 9380, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 70086, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8277, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 38021, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 105339, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8307, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 8317, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}, {'playerId': 71654, 'ownGoals': '0', 'redCards': '0', 'goals': '0', 'yellowCards': '0'}], 'substitutions': [{'playerIn': 245364, 'playerOut': 70083, 'minute': 68}, {'playerIn': 11066, 'playerOut': 340386, 'minute': 78}, {'playerIn': 265673, 'playerOut': 8325, 'minute': 83}]}, 'scoreHT': 0}}, 'seasonId': 181150, 'dateutc': '2017-08-12 16:30:00', 'winner': 1625, 'venue': 'The American Express Community Stadium', 'wyId': 2499720, 'label': 'Brighton & Hove Albion - Manchester City, 0 - 2', 'date': 'August 12, 2017 at 6:30:00 PM GMT+2', 'referees': [{'refereeId': 384965, 'role': 'referee'}, {'refereeId': 385011, 'role': 'firstAssistant'}, {'refereeId': 381936, 'role': 'secondAssistant'}, {'refereeId': 385912, 'role': 'fourthOfficial'}], 'duration': 'Regular', 'competitionId': 364}
match data
20/11/29 22:30:42 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:42 WARN BlockManager: Block input-0-1606669242400 replicated to only 0 peer(s) instead of 1 peers
{'eventId': 8, 'subEventName': 'Simple pass', 'tags': [{'id': 1801}], 'playerId': 8325, 'positions': [{'y': 53, 'x': 49}, {'y': 51, 'x': 36}], 'matchId': 2499720, 'eventName': 'Pass', 'teamId': 1625, 'matchPeriod': '1H', 'eventSec': 3.3586760000000027, 'subEventId': 85, 'id': 178147292}
Traceback (most recent call last):
  File "main.py", line 385, in <module>
    strc.awaitTermination()  
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/streaming/context.py", line 189, in awaitTermination
    self._jssc.awaitTermination()
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o92.awaitTermination.
: org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/streaming/util.py", line 68, in call
    r = self.func(t, *rdds)
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/streaming/dstream.py", line 161, in <lambda>
    func = lambda t, rdd: old_func(rdd)
  File "main.py", line 125, in calc_metrics
    metrics_values=df3.collect()[0]
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py", line 596, in collect
    sock_info = self._jdf.collectToPython()
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1304, in __call__
    return_value = get_return_value(
  File "/home/hadoop/.local/lib/python3.8/site-packages/pyspark/sql/utils.py", line 128, in deco
    return f(*a, **kw)
  File "/home/hadoop/.local/lib/python3.8/site-packages/py4j/protocol.py", line 326, in get_return_value
    raise Py4JJavaError(
py4j.protocol.Py4JJavaError: An error occurred while calling o10115.collectToPython.
: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)
	at org.codehaus.janino.UnitCompiler.access$5100(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3564)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$IfStatement.accept(Java.java:3140)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)
	at org.codehaus.janino.UnitCompiler.access$5100(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3564)
	at org.codehaus.janino.UnitCompiler$12.visitIfStatement(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$IfStatement.accept(Java.java:3140)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3598)
	at org.codehaus.janino.UnitCompiler.access$4700(UnitCompiler.java:226)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3560)
	at org.codehaus.janino.UnitCompiler$12.visitBlock(UnitCompiler.java:3542)
	at org.codehaus.janino.Java$Block.accept(Java.java:2969)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3541)
	at org.codehaus.janino.UnitCompiler.buildLocalVariableMap(UnitCompiler.java:3634)


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

20/11/29 22:30:46 ERROR JobScheduler: Error running job streaming job 1606668605000 ms.0
py4j.Py4JException: Error while sending a command.
	at py4j.CallbackClient.sendCommand(CallbackClient.java:397)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: py4j.Py4JNetworkException: Error while sending a command: null response: c
p1
call
L1606668605000
lo10117
e

	at py4j.CallbackConnection.sendCommand(CallbackConnection.java:158)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:384)
	... 21 more
hadoop@aparna-the-cyborg:~/FootballPremierLeague/backend$ 20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668610000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668615000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668620000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 WARN BlockManager: Block input-0-1606669247000 replicated to only 0 peer(s) instead of 1 peers
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668625000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668630000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668635000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668640000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668645000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668650000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR ReceiverTracker: Deregistered receiver for stream 0: Stopped by driver
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668655000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:47 ERROR JobScheduler: Error running job streaming job 1606668660000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 WARN SocketReceiver: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.run(SocketInputDStream.scala:72)
20/11/29 22:30:47 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668665000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668670000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 WARN ReceiverSupervisorImpl: Restarting receiver with delay 2000 ms: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.run(SocketInputDStream.scala:72)
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668675000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 WARN ReceiverSupervisorImpl: Receiver has been stopped
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668680000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668685000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668690000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668695000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668700000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668705000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668710000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668715000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668720000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668725000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668730000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668735000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668740000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668745000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668750000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668755000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668760000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668765000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668770000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668775000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668780000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668785000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668790000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
Exception in thread "receiver-supervisor-future-0" java.lang.Error: java.lang.InterruptedException: sleep interrupted
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1155)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.spark.streaming.receiver.ReceiverSupervisor.$anonfun$restartReceiver$1(ReceiverSupervisor.scala:196)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	... 2 more
20/11/29 22:30:48 ERROR JobScheduler: Error running job streaming job 1606668795000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:48 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668800000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668805000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668810000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668815000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668820000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668825000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668830000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668835000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668840000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668845000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668850000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668855000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668860000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668865000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668870000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR JobScheduler: Error running job streaming job 1606668875000 ms.0
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 ERROR PythonDStream$$anon$1: Cannot connect to Python process. It's probably dead. Stopping StreamingContext.
py4j.Py4JException: Error while obtaining a new communication channel
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:257)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:377)
	at py4j.CallbackClient.sendCommand(CallbackClient.java:356)
	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:106)
	at com.sun.proxy.$Proxy21.call(Unknown Source)
	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)
	at org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)
	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at java.net.Socket.connect(Socket.java:556)
	at java.net.Socket.<init>(Socket.java:452)
	at java.net.Socket.<init>(Socket.java:262)
	at javax.net.DefaultSocketFactory.createSocket(SocketFactory.java:277)
	at py4j.CallbackConnection.start(CallbackConnection.java:226)
	at py4j.CallbackClient.getConnection(CallbackClient.java:238)
	at py4j.CallbackClient.getConnectionLock(CallbackClient.java:250)
	... 22 more
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has already been stopped
20/11/29 22:30:49 WARN StreamingContext: StreamingContext has a^C

